{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace humans with Stick figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, time, pandas\n",
    "from datetime import datetime\n",
    "import os\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_PATH = \"input/parent-falling.mp4\"\n",
    "OUTPUT_PATH = \"output/replace.avi\"\n",
    "IMG_PATH = \"res/stick.png\"\n",
    "DIFF_THRESHOLD = 30\n",
    "SIZE = (600, 400)\n",
    "PROB_THRES = 0.35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video captue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use cv2 `HOGDescriptor_getDefaultPeopleDetector` to detect human bounding box. Use non-maxima suppression to combine overlapping boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Use trackers to speed up\n",
    "\n",
    "TODO: background subtraction instead of blur\n",
    "\n",
    "TODO: Better human detection\n",
    "\n",
    "TODO: Customize for different view-points and scales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-maxima suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on https://www.pyimagesearch.com/2015/02/16/faster-non-maximum-suppression-python/ \n",
    "# Malisiewicz et al.\n",
    "def non_max_suppression_fast(boxes, overlapThresh=PROB_THRES):\n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    # if the bounding boxes integers, convert them to floats --\n",
    "    # this is important since we'll be doing a bunch of divisions\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "    # initialize the list of picked indexes\t\n",
    "    pick = []\n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    "    # compute the area of the bounding boxes and sort the bounding\n",
    "    # boxes by the bottom-right y-coordinate of the bounding box\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(y2)\n",
    "    # keep looping while some indexes still remain in the indexes\n",
    "    # list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the\n",
    "        # index value to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "        # find the largest (x, y) coordinates for the start of\n",
    "        # the bounding box and the smallest (x, y) coordinates\n",
    "        # for the end of the bounding box\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "        # compute the width and height of the bounding box\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "        # compute the ratio of overlap\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "        # delete all indexes from the index list that have\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "            np.where(overlap > overlapThresh)[0])))\n",
    "    # return only the bounding boxes that were picked using the\n",
    "    # integer data type\n",
    "    return boxes[pick].astype(\"int32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read replacement image\n",
    "stick = cv2.imread(IMG_PATH, -1)\n",
    "\n",
    "# overlay image with stick figure\n",
    "def overlay_img(image, dimensions):\n",
    "    (x, y, w, h) = dimensions\n",
    "    stick_cpy = stick.copy()\n",
    "    stick_cpy = cv2.resize(stick_cpy, (w, h))\n",
    "\n",
    "    alpha_stick = stick_cpy[:, :, 3] / 255.0\n",
    "    alpha_img = 1.0 - alpha_stick\n",
    "    blurred_back = image[y:y+h, x:x+w].copy()\n",
    "    blurred_back = cv2.GaussianBlur(blurred_back, (21, 21), 0)\n",
    "\n",
    "    for c in range(0, 3):\n",
    "        image[y:y+h, x:x+w, c] = (alpha_stick * stick_cpy[:, :, c] +\n",
    "                                  alpha_img * blurred_back[:, :, c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capture video\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "width, height = SIZE\n",
    "# add HOG + SVM detector\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "# output writer\n",
    "out = cv2.VideoWriter(OUTPUT_PATH, cv2.VideoWriter_fourcc(*'DIVX'), 20, SIZE)\n",
    "\n",
    "n_skip=1\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    # skip 1 frame to speed up\n",
    "    for _ in range(n_skip):\n",
    "        _, _ = cap.read()\n",
    "    grabbed, frame = cap.read()\n",
    "    if not grabbed:\n",
    "        break\n",
    "    frame = cv2.resize(frame, SIZE)\n",
    "    \n",
    "    \n",
    "    # detect boxes and convert to numpy\n",
    "    boxes, weights = hog.detectMultiScale(frame, winStride=(8,8) )\n",
    "    boxes, weights = np.asarray(boxes), np.asarray(weights)\n",
    "    \n",
    "    # filter boxes with low weight\n",
    "    boxes = boxes[weights.flatten() > PROB_THRES]\n",
    "    boxes = non_max_suppression_fast(boxes, weights)\n",
    "    \n",
    "\n",
    "    new_frame = frame\n",
    "    for box in boxes:\n",
    "#         (x, y, w, h) = box\n",
    "        overlay_img(new_frame, box)\n",
    "    \n",
    "    # show image\n",
    "    out.write(new_frame)\n",
    "    cv2.imshow('frame',new_frame)\n",
    "    if cv2.waitKey(50) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "        \n",
    "# When everything done, release the capture\n",
    "out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}