{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace humans with Stick figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, time, pandas\n",
    "from datetime import datetime\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "DIFF_THRESHOLD = 30\n",
    "SIZE = (640, 480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATIC_BACKGROUND = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-f5f3213c1e0c>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-f5f3213c1e0c>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    IMG_PATH =\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "VIDEO_PATH = \"input/parent-falling.mp4\"\n",
    "IMG_PATH = \"res/stick.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video captue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use cv2 `HOGDescriptor_getDefaultPeopleDetector` to detect human bounding box. Use non-maxima suppression to combine overlapping boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: better human detection can be used to account for other moving object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-maxima suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import numpy as np\n",
    "# Malisiewicz et al.\n",
    "def non_max_suppression_fast(boxes, overlapThresh=0.3):\n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    # if the bounding boxes integers, convert them to floats --\n",
    "    # this is important since we'll be doing a bunch of divisions\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "    # initialize the list of picked indexes\t\n",
    "    pick = []\n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    "    # compute the area of the bounding boxes and sort the bounding\n",
    "    # boxes by the bottom-right y-coordinate of the bounding box\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(y2)\n",
    "    # keep looping while some indexes still remain in the indexes\n",
    "    # list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the\n",
    "        # index value to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "        # find the largest (x, y) coordinates for the start of\n",
    "        # the bounding box and the smallest (x, y) coordinates\n",
    "        # for the end of the bounding box\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "        # compute the width and height of the bounding box\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "        # compute the ratio of overlap\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "        # delete all indexes from the index list that have\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "            np.where(overlap > overlapThresh)[0])))\n",
    "    # return only the bounding boxes that were picked using the\n",
    "    # integer data type\n",
    "    return boxes[pick].astype(\"int32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 104 104 104\n",
      "2 208 104 104\n",
      "3 312 104 104\n",
      "4 416 104 104\n",
      "5 520 104 104\n",
      "6 624 104 104\n",
      "7 728 104 104\n",
      "8 832 104 104\n",
      "9 936 104 104\n",
      "10 1040 104 104\n",
      "11 1144 104 104\n",
      "12 1248 104 104\n",
      "13 1352 104 104\n",
      "14 1456 104 104\n",
      "15 1560 104 104\n",
      "16 1664 104 104\n",
      "17 1768 104 104\n",
      "18 1872 104 104\n",
      "19 1976 104 104\n",
      "20 2080 104 104\n",
      "21 2184 104 104\n",
      "22 2288 104 104\n",
      "23 2392 104 104\n",
      "24 2496 104 104\n",
      "25 2600 104 104\n",
      "26 2704 104 104\n",
      "27 2808 104 104\n",
      "28 2912 104 104\n",
      "29 3016 104 104\n",
      "30 3120 104 104\n",
      "31 3225 105 104\n",
      "32 3330 105 104\n",
      "33 3435 105 104\n",
      "34 3540 105 104\n",
      "35 3645 105 104\n",
      "36 3750 105 104\n",
      "37 3855 105 104\n",
      "38 3960 105 104\n",
      "39 4065 105 104\n",
      "40 4170 105 104\n",
      "41 4275 105 104\n",
      "42 4380 105 104\n",
      "43 4485 105 104\n",
      "44 4590 105 104\n",
      "45 4695 105 104\n",
      "46 4800 105 104\n",
      "47 4905 105 104\n",
      "48 5010 105 104\n",
      "49 5115 105 104\n",
      "50 5220 105 104\n",
      "51 5325 105 104\n",
      "52 5430 105 104\n",
      "53 5535 105 104\n",
      "54 5640 105 104\n",
      "55 5745 105 104\n",
      "56 5850 105 104\n",
      "57 5955 105 104\n",
      "58 6060 105 104\n",
      "59 6165 105 104\n",
      "60 6270 105 104\n",
      "61 6374 104 104\n",
      "62 6478 104 104\n",
      "63 6582 104 104\n",
      "64 6686 104 104\n",
      "65 6790 104 104\n",
      "66 6894 104 104\n",
      "67 6998 104 104\n",
      "68 7102 104 104\n",
      "69 7206 104 104\n",
      "70 7310 104 104\n",
      "71 7414 104 104\n",
      "72 7518 104 104\n",
      "73 7622 104 104\n",
      "74 7726 104 104\n",
      "75 7830 104 104\n",
      "76 7934 104 104\n",
      "77 8038 104 104\n",
      "78 8143 105 104\n",
      "79 8248 105 104\n",
      "80 8353 105 104\n",
      "81 8458 105 104\n",
      "82 8563 105 104\n",
      "83 8668 105 104\n",
      "84 8773 105 104\n",
      "85 8878 105 104\n",
      "86 8983 105 104\n",
      "87 9088 105 104\n",
      "88 9193 105 104\n",
      "89 9298 105 104\n",
      "90 9403 105 104\n",
      "91 9507 104 104\n",
      "92 9611 104 104\n",
      "93 9715 104 104\n",
      "94 9820 105 104\n",
      "95 9924 104 104\n",
      "96 10029 105 104\n",
      "97 10134 105 104\n",
      "98 10239 105 104\n",
      "99 10343 104 104\n",
      "100 10447 104 104\n",
      "101 10551 104 104\n",
      "102 10655 104 104\n",
      "103 10759 104 104\n",
      "104 10863 104 104\n",
      "105 10967 104 104\n",
      "106 11071 104 104\n",
      "107 11175 104 104\n",
      "108 11279 104 104\n",
      "109 11383 104 104\n",
      "110 11487 104 104\n",
      "111 11591 104 104\n",
      "112 11695 104 104\n",
      "113 11799 104 104\n",
      "114 11903 104 104\n",
      "115 12007 104 104\n",
      "116 12111 104 104\n",
      "117 12215 104 104\n",
      "118 12319 104 104\n",
      "119 12423 104 104\n",
      "120 12527 104 104\n",
      "121 12631 104 104\n",
      "122 12735 104 104\n",
      "123 12839 104 104\n",
      "124 12943 104 104\n",
      "125 13047 104 104\n",
      "126 13151 104 104\n",
      "127 13255 104 104\n",
      "128 13359 104 104\n",
      "129 13463 104 104\n",
      "130 13567 104 104\n",
      "131 13671 104 104\n",
      "132 13775 104 104\n",
      "133 13879 104 104\n",
      "134 13983 104 104\n",
      "135 14087 104 104\n",
      "136 14191 104 104\n",
      "137 14295 104 104\n",
      "138 14399 104 104\n",
      "139 14503 104 104\n",
      "140 14607 104 104\n",
      "141 14711 104 104\n",
      "142 14815 104 104\n",
      "143 14919 104 104\n",
      "144 15023 104 104\n",
      "145 15127 104 104\n",
      "146 15231 104 104\n",
      "147 15335 104 104\n",
      "148 15439 104 104\n",
      "149 15543 104 104\n",
      "150 15647 104 104\n",
      "151 15751 104 104\n",
      "152 15855 104 104\n",
      "153 15959 104 104\n",
      "154 16063 104 104\n",
      "155 16167 104 104\n",
      "156 16271 104 104\n",
      "157 16375 104 104\n",
      "158 16479 104 104\n",
      "159 16583 104 104\n",
      "160 16687 104 104\n",
      "161 16791 104 104\n",
      "162 16895 104 104\n",
      "163 16999 104 104\n",
      "164 17103 104 104\n",
      "165 17207 104 104\n",
      "166 17311 104 104\n",
      "167 17415 104 104\n",
      "168 17519 104 104\n",
      "169 17623 104 104\n",
      "170 17727 104 104\n",
      "171 17831 104 104\n",
      "172 17935 104 104\n",
      "173 18039 104 104\n",
      "174 18143 104 104\n",
      "175 18247 104 104\n",
      "176 18351 104 104\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "width, height = SIZE\n",
    "background_sum = np.zeros((height,width, 3), np.int32)\n",
    "background_cnt = np.zeros((height,width, 3), np.int32)\n",
    "prev_img = None\n",
    "\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "stick = imread(\"\")\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.resize(frame, SIZE)\n",
    "    frame = cv2.GaussianBlur(frame, (7, 7), 0)\n",
    "\n",
    "    # Our operations on the frame come here\n",
    "#     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#     gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "\n",
    "    # compute difference\n",
    "#     diff_frame = cv2.absdiff(prev_img, gray)\n",
    "#     thresh_frame = cv2.threshold(diff_frame, DIFF_THRESHOLD, 255, cv2.THRESH_BINARY)[1]\n",
    "#     thresh_frame = cv2.dilate(thresh_frame, None, iterations=2)\n",
    "#     prev_img = gray\n",
    "    \n",
    "    addition = frame\n",
    "    \n",
    "    boxes, weights = hog.detectMultiScale(frame, winStride=(8,8) )\n",
    "    boxes, weights = np.asarray(boxes), np.asarray(weights)\n",
    "    boxes = boxes[weights.flatten() > 0.5]\n",
    "    boxes = non_max_suppression_fast(boxes, weights)\n",
    "    \n",
    "#     cnts, _ = cv2.findContours(thresh_frame.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for box in boxes:\n",
    "        (x, y, w, h) = box\n",
    "        addition[y:y+h, x:x+w, :] = 0\n",
    "#         cv2.rectangle(addition, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "        \n",
    "    \n",
    "#     for contour in cnts:\n",
    "#         if cv2.contourArea(contour) < 100:\n",
    "#             continue\n",
    "#         (x, y, w, h) = cv2.boundingRect(contour)\n",
    "#         addition[x:x+w, y:y+h, :] = 0\n",
    "#         cv2.rectangle(addition, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "    \n",
    "    cv2.imshow('frame',addition)\n",
    "    cv2.waitKey(1)\n",
    "    background_sum += addition\n",
    "    background_cnt += 1 * (addition > 0)\n",
    "    display_cnt = background_cnt\n",
    "    display_cnt[display_cnt == 0] = 1 \n",
    "    display_frame = background_sum // display_cnt\n",
    "    cv2.imwrite('color_img.jpg', display_frame)\n",
    "#     print(display_cnt[10, 10, 1],background_sum[10, 10, 1], frame[10, 10, 1], display_frame[10, 10, 1])\n",
    "    img = cv2.imread('color_img.jpg', 0)\n",
    "    cv2.imshow('back',img)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "        \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
